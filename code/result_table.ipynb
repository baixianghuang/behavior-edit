{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/behavior-edit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "\n",
    "edit_method_order_ls = ['ICE', 'ROME', 'FT-M']\n",
    "colors = ['#91b88d', '#a3efef', '#ffd27f', '#cc9d9d']\n",
    "model_include_ls = ['llama2-7b', 'llama3-8b', 'mistral-7b', 'qwen3-8b', 'olmo2-7b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing a behavior under a specific circumstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_method</th>\n",
       "      <th>direction</th>\n",
       "      <th>model</th>\n",
       "      <th>efficacy_pre</th>\n",
       "      <th>efficacy_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2bad</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2bad</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>46.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2bad</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>51.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2bad</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2bad</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>43.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2bad</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2bad</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>46.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2bad</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>51.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2bad</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>50.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2bad</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>43.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2bad</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2bad</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>46.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2bad</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>51.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2bad</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2bad</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>43.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edit_method direction       model  efficacy_pre  efficacy_post\n",
       "3          ICE      2bad   llama2-7b           3.0          100.0\n",
       "5          ICE      2bad   llama3-8b          46.0           56.0\n",
       "7          ICE      2bad  mistral-7b          51.0           60.0\n",
       "9          ICE      2bad    olmo2-7b          50.0          100.0\n",
       "11         ICE      2bad    qwen3-8b          43.0          100.0\n",
       "16        ROME      2bad   llama2-7b           3.0          100.0\n",
       "18        ROME      2bad   llama3-8b          46.0          100.0\n",
       "20        ROME      2bad  mistral-7b          51.0          100.0\n",
       "22        ROME      2bad    olmo2-7b          50.0           99.0\n",
       "24        ROME      2bad    qwen3-8b          43.0          100.0\n",
       "29        FT-M      2bad   llama2-7b           3.0          100.0\n",
       "31        FT-M      2bad   llama3-8b          46.0          100.0\n",
       "33        FT-M      2bad  mistral-7b          51.0          100.0\n",
       "35        FT-M      2bad    olmo2-7b          50.0          100.0\n",
       "37        FT-M      2bad    qwen3-8b          43.0          100.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_results(folder, edit_method_order_ls=None, direction=None):\n",
    "    metrics_ls = []\n",
    "    for model_name in sorted(os.listdir(folder)):\n",
    "        model_folder = os.path.join(folder, model_name)\n",
    "        for filename in sorted(os.listdir(model_folder)):\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(model_folder, filename)\n",
    "                with open(filepath, 'r') as file:\n",
    "                    metrics = json.load(file)\n",
    "                    parts = filename.split('_')\n",
    "\n",
    "                    results = {\n",
    "                        \"direction\": parts[1].replace('.json', ''),\n",
    "                        \"model\": model_name,\n",
    "                        \"edit_method\": parts[0],\n",
    "                        \"efficacy_pre\": get_avg_std([e['pre']['rewrite_acc'] for e in metrics]),\n",
    "                        \"efficacy_post\": get_avg_std([e['post']['rewrite_acc'] for e in metrics]),\n",
    "                    }\n",
    "                    metrics_ls.append(results)\n",
    "    df = pd.DataFrame(metrics_ls)\n",
    "    if edit_method_order_ls:\n",
    "        df = df.set_index('edit_method').loc[edit_method_order_ls].reset_index()\n",
    "    if direction:\n",
    "        df = df[df['direction'] == direction]\n",
    "    if model_include_ls:\n",
    "        df = df[df['model'].isin(model_include_ls)]\n",
    "    return df\n",
    "\n",
    "path_prefix = \"../results/specific/\"\n",
    "datasets = [\n",
    "    {\"path\": f\"{path_prefix}socialchemistry-100\", \"direction\": \"2bad\"},\n",
    "    {\"path\": f\"{path_prefix}ethics-hard-short\", \"direction\": \"2bad\"},\n",
    "    {\"path\": f\"{path_prefix}moralchoice-open-high-ambiguity\", \"direction\": \"2bad\"},\n",
    "    {\"path\": f\"{path_prefix}socialchemistry-100\", \"direction\": \"2good\"},\n",
    "    {\"path\": f\"{path_prefix}ethics-hard-short\", \"direction\": \"2good\"},\n",
    "    {\"path\": f\"{path_prefix}moralchoice-open-high-ambiguity\", \"direction\": \"2abstention\"},\n",
    "]\n",
    "summarize_results(datasets[0]['path'], edit_method_order_ls, datasets[0]['direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_method</th>\n",
       "      <th>direction</th>\n",
       "      <th>model</th>\n",
       "      <th>efficacy_pre</th>\n",
       "      <th>efficacy_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2good</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2good</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>52.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2good</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>49.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2good</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ICE</td>\n",
       "      <td>2good</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2good</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2good</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2good</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2good</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>50.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ROME</td>\n",
       "      <td>2good</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2good</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2good</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2good</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2good</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>2good</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edit_method direction       model  efficacy_pre  efficacy_post\n",
       "4          ICE     2good   llama2-7b          19.0          100.0\n",
       "6          ICE     2good   llama3-8b          52.0           98.0\n",
       "8          ICE     2good  mistral-7b          49.0           54.0\n",
       "10         ICE     2good    olmo2-7b          50.0           52.0\n",
       "12         ICE     2good    qwen3-8b          47.0           56.0\n",
       "17        ROME     2good   llama2-7b          19.0          100.0\n",
       "19        ROME     2good   llama3-8b          52.0          100.0\n",
       "21        ROME     2good  mistral-7b          49.0          100.0\n",
       "23        ROME     2good    olmo2-7b          50.0           92.0\n",
       "25        ROME     2good    qwen3-8b          47.0          100.0\n",
       "30        FT-M     2good   llama2-7b          19.0          100.0\n",
       "32        FT-M     2good   llama3-8b          52.0          100.0\n",
       "34        FT-M     2good  mistral-7b          49.0          100.0\n",
       "36        FT-M     2good    olmo2-7b          50.0          100.0\n",
       "38        FT-M     2good    qwen3-8b          47.0          100.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(datasets[3]['path'], edit_method_order_ls, datasets[3]['direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>edit_method</th>\n",
       "      <th>model</th>\n",
       "      <th>efficacy_pre</th>\n",
       "      <th>efficacy_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-reasoner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-reasoner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash-lite</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash-lite</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-pro-preview-03-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-pro-preview-05-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-2-1212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-2-1212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>llama-4-maverick-17b-128e-instruct-fp8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>llama-4-maverick-17b-128e-instruct-fp8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>llama3.1-405b-instruct-fp8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>llama3.1-405b-instruct-fp8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2bad</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2good</td>\n",
       "      <td>ICE</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   direction edit_method                                   model  \\\n",
       "0       2bad         ICE               claude-3-5-haiku-20241022   \n",
       "1      2good         ICE               claude-3-5-haiku-20241022   \n",
       "2       2bad         ICE              claude-3-5-sonnet-20240620   \n",
       "3      2good         ICE              claude-3-5-sonnet-20240620   \n",
       "4       2bad         ICE              claude-3-7-sonnet-20250219   \n",
       "5      2good         ICE              claude-3-7-sonnet-20250219   \n",
       "6       2bad         ICE                 claude-3-haiku-20240307   \n",
       "7      2good         ICE                 claude-3-haiku-20240307   \n",
       "10      2bad         ICE                           deepseek-chat   \n",
       "11     2good         ICE                           deepseek-chat   \n",
       "12      2bad         ICE                       deepseek-reasoner   \n",
       "13     2good         ICE                       deepseek-reasoner   \n",
       "14      2bad         ICE                        gemini-1.5-flash   \n",
       "15     2good         ICE                        gemini-1.5-flash   \n",
       "16      2bad         ICE                        gemini-2.0-flash   \n",
       "17     2good         ICE                        gemini-2.0-flash   \n",
       "18      2bad         ICE                   gemini-2.0-flash-lite   \n",
       "19     2good         ICE                   gemini-2.0-flash-lite   \n",
       "20      2bad         ICE          gemini-2.5-flash-preview-04-17   \n",
       "21     2good         ICE          gemini-2.5-flash-preview-04-17   \n",
       "22      2bad         ICE            gemini-2.5-pro-preview-03-25   \n",
       "23     2good         ICE            gemini-2.5-pro-preview-05-06   \n",
       "26      2bad         ICE                                 gpt-4.1   \n",
       "27     2good         ICE                                 gpt-4.1   \n",
       "28      2bad         ICE                            gpt-4.1-mini   \n",
       "29     2good         ICE                            gpt-4.1-mini   \n",
       "30      2bad         ICE                            gpt-4.1-nano   \n",
       "31     2good         ICE                            gpt-4.1-nano   \n",
       "32      2bad         ICE                                  gpt-4o   \n",
       "33     2good         ICE                                  gpt-4o   \n",
       "34      2bad         ICE                             gpt-4o-mini   \n",
       "35     2good         ICE                             gpt-4o-mini   \n",
       "38      2bad         ICE                             grok-2-1212   \n",
       "39     2good         ICE                             grok-2-1212   \n",
       "40      2bad         ICE                             grok-3-beta   \n",
       "41     2good         ICE                             grok-3-beta   \n",
       "42      2bad         ICE  llama-4-maverick-17b-128e-instruct-fp8   \n",
       "43     2good         ICE  llama-4-maverick-17b-128e-instruct-fp8   \n",
       "48      2bad         ICE              llama3.1-405b-instruct-fp8   \n",
       "49     2good         ICE              llama3.1-405b-instruct-fp8   \n",
       "52      2bad         ICE                                      o1   \n",
       "53     2good         ICE                                      o1   \n",
       "54      2bad         ICE                                      o3   \n",
       "55     2good         ICE                                      o3   \n",
       "56      2bad         ICE                                 o3-mini   \n",
       "57     2good         ICE                                 o3-mini   \n",
       "58      2bad         ICE                                 o4-mini   \n",
       "59     2good         ICE                                 o4-mini   \n",
       "\n",
       "    efficacy_pre  efficacy_post  \n",
       "0            0.0           63.0  \n",
       "1            2.0           99.0  \n",
       "2            0.0           55.0  \n",
       "3            6.0          100.0  \n",
       "4            0.0           46.0  \n",
       "5            2.0          100.0  \n",
       "6            0.0           75.0  \n",
       "7           13.0          100.0  \n",
       "10           0.0           96.0  \n",
       "11           2.0           99.0  \n",
       "12           0.0           82.0  \n",
       "13           4.0           95.0  \n",
       "14           0.0           93.0  \n",
       "15           9.0          100.0  \n",
       "16           0.0          100.0  \n",
       "17           5.0          100.0  \n",
       "18           0.0          100.0  \n",
       "19           4.0          100.0  \n",
       "20           0.0           99.0  \n",
       "21           1.0          100.0  \n",
       "22           0.0           80.0  \n",
       "23           3.0          100.0  \n",
       "26           0.0          100.0  \n",
       "27           0.0          100.0  \n",
       "28           0.0          100.0  \n",
       "29           0.0          100.0  \n",
       "30           0.0          100.0  \n",
       "31           0.0          100.0  \n",
       "32           0.0           99.0  \n",
       "33           0.0          100.0  \n",
       "34           0.0          100.0  \n",
       "35           0.0          100.0  \n",
       "38           0.0          100.0  \n",
       "39           1.0          100.0  \n",
       "40           0.0           99.0  \n",
       "41           1.0          100.0  \n",
       "42           0.0           94.0  \n",
       "43           3.0          100.0  \n",
       "48           0.0           77.0  \n",
       "49           3.0          100.0  \n",
       "52           0.0           90.0  \n",
       "53           0.0          100.0  \n",
       "54           0.0           74.0  \n",
       "55           0.0          100.0  \n",
       "56           0.0           96.0  \n",
       "57           0.0          100.0  \n",
       "58           0.0           50.0  \n",
       "59           0.0           99.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_exclude = ['llama2-7b', 'llama3-8b', 'mistral-7b', 'gpt-j-6b', 'deepseek-7b', 'qwen3-8b', 'gemma-7b', 'olmo2-7b']\n",
    "\n",
    "def summarize_results_proprietary(folder, direction=None, ice_only=False, general_metric=False):\n",
    "    metrics_ls = []\n",
    "    for model_name in sorted(os.listdir(folder)):\n",
    "        model_folder = os.path.join(folder, model_name)\n",
    "        for filename in sorted(os.listdir(model_folder)):\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(model_folder, filename)\n",
    "                with open(filepath, 'r') as file:\n",
    "                    metrics = json.load(file)\n",
    "                    parts = filename.split('_')\n",
    "\n",
    "                    results = {\n",
    "                        \"direction\": parts[1].replace('.json', ''),\n",
    "                        \"edit_method\": parts[0],\n",
    "                        \"model\": model_name,\n",
    "                        \"efficacy_pre\": get_avg_std([e['pre']['rewrite_acc'] for e in metrics]),\n",
    "                        \"efficacy_post\": get_avg_std([e['post']['rewrite_acc'] for e in metrics]),\n",
    "                    }\n",
    "                    if general_metric:\n",
    "                        if 'rephrase_acc' in metrics[0]['pre']:\n",
    "                            results['rephrase_pre'] = get_avg_std([e['pre']['rephrase_acc'] for e in metrics])\n",
    "                            results['rephrase_post'] = get_avg_std([e['post']['rephrase_acc'] for e in metrics])\n",
    "                        if 'yes_question' in metrics[0]['pre']:\n",
    "                            results['yes_pre'] = get_avg_std([e['pre']['yes_question']['yes_acc'] for e in metrics])\n",
    "                            results['yes_post'] = get_avg_std([e['post']['yes_question']['yes_acc'] for e in metrics])\n",
    "                        if 'no_question' in metrics[0]['pre']:\n",
    "                            results['no_pre'] = get_avg_std([e['pre']['no_question']['no_acc'] for e in metrics])\n",
    "                            results['no_post'] = get_avg_std([e['post']['no_question']['no_acc'] for e in metrics])\n",
    "                        if 'two_choice_question' in metrics[0]['pre']:\n",
    "                            results['two_choice_pre'] = get_avg_std([e['pre']['two_choice_question']['two_choice_acc'] for e in metrics])\n",
    "                            results['two_choice_post'] = get_avg_std([e['post']['two_choice_question']['two_choice_acc'] for e in metrics])\n",
    "                        if 'open_question' in metrics[0]['pre']:\n",
    "                            results['open_pre'] = get_avg_std([e['pre']['open_question']['open_acc'] for e in metrics])\n",
    "                            results['open_post'] = get_avg_std([e['post']['open_question']['open_acc'] for e in metrics])\n",
    "                    if ice_only:\n",
    "                        if 'ICE' == parts[0]:\n",
    "                            metrics_ls.append(results)\n",
    "                    else:  # include ICE variants\n",
    "                        if 'ICE' in parts[0]:\n",
    "                            metrics_ls.append(results)\n",
    "\n",
    "    df = pd.DataFrame(metrics_ls)\n",
    "    df = df[~df['model'].isin(models_to_exclude)]\n",
    "    if direction:\n",
    "        df = df[df['direction'] == direction]\n",
    "    return df\n",
    "\n",
    "summarize_results_proprietary(\"../results/specific/moralchoice-open-low-ambiguity\", ice_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact on overall morality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the df get from moral_impact_res() to bar plot, each model should have 1 bar with grey color for pre_edit value (which is same for same model) (number of edit_method) bars for post_edit value of each edit_method. Use edit_method as hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_data_name: socialchemistry-100, data size: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_method</th>\n",
       "      <th>model</th>\n",
       "      <th>direction</th>\n",
       "      <th>acc_pre</th>\n",
       "      <th>acc_post</th>\n",
       "      <th>acc_post_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>94.29</td>\n",
       "      <td>74.00</td>\n",
       "      <td>24.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICE</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>94.29</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ROME</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>94.29</td>\n",
       "      <td>86.25</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.95</td>\n",
       "      <td>58.85</td>\n",
       "      <td>18.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICE</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.95</td>\n",
       "      <td>86.50</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ROME</td>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.95</td>\n",
       "      <td>73.50</td>\n",
       "      <td>22.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>97.00</td>\n",
       "      <td>73.25</td>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICE</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>97.00</td>\n",
       "      <td>60.25</td>\n",
       "      <td>14.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ROME</td>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>97.00</td>\n",
       "      <td>87.69</td>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICE</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROME</td>\n",
       "      <td>olmo2-7b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.25</td>\n",
       "      <td>24.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FT-M</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.88</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICE</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.88</td>\n",
       "      <td>95.59</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROME</td>\n",
       "      <td>qwen3-8b</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.88</td>\n",
       "      <td>84.30</td>\n",
       "      <td>18.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edit_method       model direction  acc_pre  acc_post  acc_post_std\n",
       "13        FT-M   llama2-7b      2bad    94.29     74.00         24.01\n",
       "1          ICE   llama2-7b      2bad    94.29     50.00          0.00\n",
       "7         ROME   llama2-7b      2bad    94.29     86.25         34.47\n",
       "14        FT-M   llama3-8b      2bad    98.95     58.85         18.87\n",
       "2          ICE   llama3-8b      2bad    98.95     86.50          4.77\n",
       "8         ROME   llama3-8b      2bad    98.95     73.50         22.52\n",
       "15        FT-M  mistral-7b      2bad    97.00     73.25         23.25\n",
       "3          ICE  mistral-7b      2bad    97.00     60.25         14.94\n",
       "9         ROME  mistral-7b      2bad    97.00     87.69         12.46\n",
       "16        FT-M    olmo2-7b      2bad   100.00     75.00         25.00\n",
       "4          ICE    olmo2-7b      2bad   100.00     99.50          0.50\n",
       "10        ROME    olmo2-7b      2bad   100.00     75.25         24.75\n",
       "17        FT-M    qwen3-8b      2bad    98.88     50.00          0.00\n",
       "5          ICE    qwen3-8b      2bad    98.88     95.59          0.43\n",
       "11        ROME    qwen3-8b      2bad    98.88     84.30         18.83"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moral_impact_res(eval_data_path, steer_direction='2bad', edit_method_order_ls=edit_method_order_ls, model_include_ls=model_include_ls):\n",
    "    eval_data_name = eval_data_path.split('/')[-1].split('_')[-1]\n",
    "    questions, targets, circumstances, _, full_prompts, action_dict = load_ae_dataset(eval_data_name, steer_direction, None)\n",
    "    num_edits = 99\n",
    "    results_post = []\n",
    "    for edit_method_dir in os.listdir(eval_data_path):\n",
    "        parts = edit_method_dir.split('_')\n",
    "        post_edit_path = os.path.join(eval_data_path, edit_method_dir)\n",
    "        if post_edit_path.endswith('.json'):\n",
    "            post_edit_df = pd.read_json(post_edit_path)\n",
    "        else:\n",
    "            post_edit_df = pd.read_csv(post_edit_path)\n",
    "        responses_pre = post_edit_df['pre_edit'].tolist()\n",
    "        responses_post = post_edit_df['post_edit'].tolist()\n",
    "        responses_norm_pre = post_edit_df['pre_edit_norm'].tolist()\n",
    "        responses_norm_post = post_edit_df['post_edit_norm'].tolist()\n",
    "        labels = post_edit_df['label'].tolist()\n",
    "\n",
    "        acc_pre, _, _, abstention_rate_pre, invalid_pre = eval_acc_abstention(questions, targets, labels, steer_direction, responses_pre, responses_norm_pre, full_prompts=full_prompts, data_name=eval_data_name, action_dict=action_dict)\n",
    "        acc_post, _, _, abstention_rate_post, invalid_post = eval_acc_abstention(questions, targets, labels, steer_direction, responses_post, responses_norm_post, full_prompts=full_prompts, data_name=eval_data_name, action_dict=action_dict)\n",
    "\n",
    "        # Calculate standard deviations across different runs\n",
    "        edit_indices = post_edit_df[\"edit_idx\"].unique()\n",
    "        acc_post_runs = []\n",
    "        for edit_idx in edit_indices:\n",
    "            run_df = post_edit_df[post_edit_df[\"edit_idx\"] == edit_idx]\n",
    "            run_responses = run_df['post_edit_norm'].tolist()\n",
    "            run_labels = run_df['label'].tolist()\n",
    "            run_acc = sum([1 if r == gt else 0 for r, gt in zip(run_responses, run_labels)]) / len(run_labels)\n",
    "            acc_post_runs.append(run_acc * 100)\n",
    "        \n",
    "        acc_post_std = np.std(acc_post_runs)\n",
    "\n",
    "        results_post.append({\n",
    "            'model': parts[1],\n",
    "            'edit_method': parts[0],\n",
    "            'direction': parts[2],\n",
    "            'acc_pre': round(acc_pre * 100, 2),\n",
    "            'acc_post': round(acc_post * 100, 2), # avg acc over 5 independent edits\n",
    "            'acc_post_std': round(acc_post_std, 2),\n",
    "            # 'abstention_pre': round(abstention_rate_pre * 100, 2),\n",
    "            # 'abstention_post': round(abstention_rate_post * 100, 2),\n",
    "            # 'invalid_pre': round(invalid_pre * 100, 2),\n",
    "            # 'invalid_post': round(invalid_post * 100, 2),\n",
    "            # 'valid_pre': round((1 - invalid_pre - abstention_rate_pre) * 100, 2),\n",
    "            # 'valid_post': round((1 - invalid_post - abstention_rate_post) * 100, 2)\n",
    "        })\n",
    "        num_edits = min(num_edits, post_edit_df[\"edit_idx\"].nunique())\n",
    "    if 'rules' in eval_data_path.split('/')[-1] or 'common-morality' in eval_data_path.split('/')[-1]:\n",
    "        print(f'eval_data_name: {eval_data_name}, Number of edits: {num_edits}')\n",
    "    else:\n",
    "        print(f'eval_data_name: {eval_data_name}, data size: {len(questions)}')\n",
    "        \n",
    "    df = pd.DataFrame(results_post).sort_values(by=['model', 'edit_method'])\n",
    "    if edit_method_order_ls:\n",
    "        df = df.set_index('edit_method').loc[edit_method_order_ls].reset_index()\n",
    "    df = df[df.direction == steer_direction]\n",
    "    if model_include_ls:\n",
    "        df = df[df['model'].isin(model_include_ls)]\n",
    "    return df.sort_values(by=['model', 'edit_method'])\n",
    "\n",
    "datasets = [\n",
    "    {\"path\": \"../results/impact/socialchemistry-100\", \"direction\": \"2bad\"},\n",
    "    {\"path\": \"../results/impact/ethics-short\", \"direction\": \"2bad\"},\n",
    "    {\"path\": \"../results/impact/moralchoice-two-choice-low-ambiguity\", \"title\": \"Low-Ambiguity MoralChoice\", \"direction\": \"2bad\"},\n",
    "    {\"path\": \"../results/impact/jiminy-subset\", \"title\": \"Jiminy Cricket Subset\", \"direction\": \"2bad\"},\n",
    "    {\"path\": \"../results/impact/ethics-hard-short\", \"direction\": \"2bad\"},\n",
    "    {\"path\": \"../results/impact/moralchoice-two-choice-high-ambiguity\", \"title\": \"High-Ambiguity MoralChoice\", \"direction\": \"2bad\"},\n",
    "]\n",
    "moral_impact_res(datasets[0]['path'], datasets[0]['direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_data_name: moralchoice-open-low-ambiguity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_method</th>\n",
       "      <th>model</th>\n",
       "      <th>direction</th>\n",
       "      <th>acc_pre</th>\n",
       "      <th>acc_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.84</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.85</td>\n",
       "      <td>28.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.90</td>\n",
       "      <td>9.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.70</td>\n",
       "      <td>20.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.84</td>\n",
       "      <td>8.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-reasoner</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.67</td>\n",
       "      <td>20.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>2bad</td>\n",
       "      <td>97.44</td>\n",
       "      <td>22.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash-lite</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.77</td>\n",
       "      <td>26.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-pro-preview-05-06</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.85</td>\n",
       "      <td>20.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.84</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.84</td>\n",
       "      <td>12.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>21.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.84</td>\n",
       "      <td>21.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-2-1212</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.91</td>\n",
       "      <td>9.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.92</td>\n",
       "      <td>8.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICE</td>\n",
       "      <td>llama-4-maverick-17b-128e-instruct-fp8</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.82</td>\n",
       "      <td>18.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ICE</td>\n",
       "      <td>llama3.1-405b-instruct-fp8</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o1</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.77</td>\n",
       "      <td>40.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o3</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>40.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>98.90</td>\n",
       "      <td>14.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>100.00</td>\n",
       "      <td>37.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edit_method                                   model direction  acc_pre  \\\n",
       "6          ICE               claude-3-5-haiku-20241022      2bad    98.84   \n",
       "14         ICE              claude-3-5-sonnet-20240620      2bad    98.85   \n",
       "13         ICE              claude-3-7-sonnet-20250219      2bad    98.90   \n",
       "11         ICE                 claude-3-haiku-20240307      2bad    98.70   \n",
       "4          ICE                           deepseek-chat      2bad    98.84   \n",
       "10         ICE                       deepseek-reasoner      2bad    98.67   \n",
       "15         ICE                        gemini-1.5-flash      2bad   100.00   \n",
       "19         ICE                        gemini-2.0-flash      2bad    97.44   \n",
       "5          ICE                   gemini-2.0-flash-lite      2bad    98.77   \n",
       "20         ICE          gemini-2.5-flash-preview-04-17      2bad   100.00   \n",
       "18         ICE            gemini-2.5-pro-preview-05-06      2bad    98.85   \n",
       "17         ICE                                 gpt-4.1      2bad    98.84   \n",
       "2          ICE                            gpt-4.1-mini      2bad    98.84   \n",
       "3          ICE                            gpt-4.1-nano      2bad   100.00   \n",
       "8          ICE                                  gpt-4o      2bad    98.84   \n",
       "9          ICE                             gpt-4o-mini      2bad   100.00   \n",
       "22         ICE                             grok-2-1212      2bad    98.91   \n",
       "21         ICE                             grok-3-beta      2bad    98.92   \n",
       "0          ICE  llama-4-maverick-17b-128e-instruct-fp8      2bad    98.82   \n",
       "12         ICE              llama3.1-405b-instruct-fp8      2bad   100.00   \n",
       "7          ICE                                      o1      2bad    98.77   \n",
       "16         ICE                                      o3      2bad   100.00   \n",
       "23         ICE                                 o3-mini      2bad    98.90   \n",
       "1          ICE                                 o4-mini      2bad   100.00   \n",
       "\n",
       "    acc_post  \n",
       "6      18.00  \n",
       "14     28.69  \n",
       "13      9.37  \n",
       "11     20.39  \n",
       "4       8.73  \n",
       "10     20.69  \n",
       "15     24.19  \n",
       "19     22.88  \n",
       "5      26.01  \n",
       "20     24.68  \n",
       "18     20.35  \n",
       "17      7.45  \n",
       "2      12.03  \n",
       "3      21.86  \n",
       "8      21.48  \n",
       "9      11.35  \n",
       "22      9.91  \n",
       "21      8.77  \n",
       "0      18.94  \n",
       "12     15.44  \n",
       "7      40.58  \n",
       "16     40.37  \n",
       "23     14.34  \n",
       "1      37.99  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moral_impact_res_proprietary(eval_data_path, steer_direction='2bad'):\n",
    "    eval_data_name = eval_data_path.split('/')[-1].split('_')[-1]\n",
    "    results_post = []\n",
    "    for edit_method_dir in os.listdir(eval_data_path):\n",
    "        parts = edit_method_dir.split('_')\n",
    "        post_edit_path = os.path.join(eval_data_path, edit_method_dir)\n",
    "        post_edit_df = pd.read_json(post_edit_path)\n",
    "\n",
    "        results_post.append({\n",
    "            'edit_method': parts[0],\n",
    "            'model': parts[1],\n",
    "            'direction': parts[2],\n",
    "            'acc_pre': round(post_edit_df['pre_acc'].mean() * 100, 2),\n",
    "            'acc_post': round(post_edit_df['post_acc'].mean() * 100, 2),\n",
    "        })\n",
    "    print(f'eval_data_name: {eval_data_name}')\n",
    "    df = pd.DataFrame(results_post).sort_values(by=['model'])\n",
    "    return df[df.direction == steer_direction]\n",
    "\n",
    "\n",
    "moral_impact_res_proprietary(\"../results/impact-api/moralchoice-open-low-ambiguity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_data_name: moralchoice-open-high-ambiguity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_method</th>\n",
       "      <th>model</th>\n",
       "      <th>direction</th>\n",
       "      <th>acc_pre</th>\n",
       "      <th>acc_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>2bad</td>\n",
       "      <td>78.18</td>\n",
       "      <td>47.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>2bad</td>\n",
       "      <td>73.53</td>\n",
       "      <td>46.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>2bad</td>\n",
       "      <td>76.71</td>\n",
       "      <td>40.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICE</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>2bad</td>\n",
       "      <td>75.51</td>\n",
       "      <td>38.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>2bad</td>\n",
       "      <td>76.81</td>\n",
       "      <td>37.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ICE</td>\n",
       "      <td>deepseek-reasoner</td>\n",
       "      <td>2bad</td>\n",
       "      <td>79.66</td>\n",
       "      <td>41.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>2bad</td>\n",
       "      <td>82.61</td>\n",
       "      <td>30.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>2bad</td>\n",
       "      <td>79.63</td>\n",
       "      <td>31.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.0-flash-lite</td>\n",
       "      <td>2bad</td>\n",
       "      <td>75.44</td>\n",
       "      <td>30.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17</td>\n",
       "      <td>2bad</td>\n",
       "      <td>82.00</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gemini-2.5-pro-preview-05-06</td>\n",
       "      <td>2bad</td>\n",
       "      <td>80.25</td>\n",
       "      <td>37.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>2bad</td>\n",
       "      <td>75.68</td>\n",
       "      <td>34.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>80.88</td>\n",
       "      <td>35.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>2bad</td>\n",
       "      <td>72.46</td>\n",
       "      <td>69.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>2bad</td>\n",
       "      <td>80.33</td>\n",
       "      <td>61.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ICE</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>78.46</td>\n",
       "      <td>33.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-2-1212</td>\n",
       "      <td>2bad</td>\n",
       "      <td>74.39</td>\n",
       "      <td>30.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ICE</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>2bad</td>\n",
       "      <td>85.33</td>\n",
       "      <td>28.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ICE</td>\n",
       "      <td>llama-4-maverick-17b-128e-instruct-fp8</td>\n",
       "      <td>2bad</td>\n",
       "      <td>72.37</td>\n",
       "      <td>35.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ICE</td>\n",
       "      <td>llama3.1-405b-instruct-fp8</td>\n",
       "      <td>2bad</td>\n",
       "      <td>77.03</td>\n",
       "      <td>31.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o1</td>\n",
       "      <td>2bad</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o3</td>\n",
       "      <td>2bad</td>\n",
       "      <td>75.00</td>\n",
       "      <td>58.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>78.08</td>\n",
       "      <td>37.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICE</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>2bad</td>\n",
       "      <td>71.60</td>\n",
       "      <td>55.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edit_method                                   model direction  acc_pre  \\\n",
       "4          ICE               claude-3-5-haiku-20241022      2bad    78.18   \n",
       "13         ICE              claude-3-5-sonnet-20240620      2bad    73.53   \n",
       "5          ICE              claude-3-7-sonnet-20250219      2bad    76.71   \n",
       "2          ICE                 claude-3-haiku-20240307      2bad    75.51   \n",
       "8          ICE                           deepseek-chat      2bad    76.81   \n",
       "14         ICE                       deepseek-reasoner      2bad    79.66   \n",
       "15         ICE                        gemini-1.5-flash      2bad    82.61   \n",
       "18         ICE                        gemini-2.0-flash      2bad    79.63   \n",
       "6          ICE                   gemini-2.0-flash-lite      2bad    75.44   \n",
       "9          ICE          gemini-2.5-flash-preview-04-17      2bad    82.00   \n",
       "12         ICE            gemini-2.5-pro-preview-05-06      2bad    80.25   \n",
       "23         ICE                                 gpt-4.1      2bad    75.68   \n",
       "7          ICE                            gpt-4.1-mini      2bad    80.88   \n",
       "1          ICE                            gpt-4.1-nano      2bad    72.46   \n",
       "21         ICE                                  gpt-4o      2bad    80.33   \n",
       "10         ICE                             gpt-4o-mini      2bad    78.46   \n",
       "3          ICE                             grok-2-1212      2bad    74.39   \n",
       "17         ICE                             grok-3-beta      2bad    85.33   \n",
       "20         ICE  llama-4-maverick-17b-128e-instruct-fp8      2bad    72.37   \n",
       "19         ICE              llama3.1-405b-instruct-fp8      2bad    77.03   \n",
       "16         ICE                                      o1      2bad    74.32   \n",
       "11         ICE                                      o3      2bad    75.00   \n",
       "22         ICE                                 o3-mini      2bad    78.08   \n",
       "0          ICE                                 o4-mini      2bad    71.60   \n",
       "\n",
       "    acc_post  \n",
       "4      47.17  \n",
       "13     46.98  \n",
       "5      40.16  \n",
       "2      38.98  \n",
       "8      37.12  \n",
       "14     41.22  \n",
       "15     30.52  \n",
       "18     31.45  \n",
       "6      30.60  \n",
       "9      35.82  \n",
       "12     37.88  \n",
       "23     34.32  \n",
       "7      35.12  \n",
       "1      69.59  \n",
       "21     61.11  \n",
       "10     33.50  \n",
       "3      30.23  \n",
       "17     28.49  \n",
       "20     35.71  \n",
       "19     31.28  \n",
       "16     66.07  \n",
       "11     58.29  \n",
       "22     37.92  \n",
       "0      55.67  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moral_impact_res_proprietary(\"../results/impact-api/moralchoice-open-high-ambiguity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavior-edit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
